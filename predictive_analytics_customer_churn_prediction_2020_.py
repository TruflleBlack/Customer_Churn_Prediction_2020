# -*- coding: utf-8 -*-
"""Predictive Analytics Customer Churn Prediction 2020 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X15so-V8Z6xKcCsyhqnjgtFo-_5nyYYH

# Data Understanding

## Importing python modules
"""

!pip install opendatasets
!pip install pandas

# Commented out IPython magic to ensure Python compatibility.
import opendatasets as od
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import plot_confusion_matrix, classification_report
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import mean_squared_error

"""## Load Data in a Dataframe using pandas"""

df=pd.read_csv("drive/MyDrive/Dataset/train.csv")
df.tail()

df.iloc[552]

"""## Variable Description"""

df.info()

"""## Count the number of missing values in each column"""

df.isna().sum()

df.shape

"""## See how many unique entries there are"""

print('State : ',df.state.unique())
print('Account Length : ',df.account_length.unique())
print('Area Code : ',df.area_code.unique())
print('International Plan : ',df.international_plan.unique())
print('Voice Mail Plan : ',df.voice_mail_plan.unique())
print('Number Vmail Messages : ',df.number_vmail_messages.unique())
print('Total Day Minutes : ',df.total_day_minutes.unique())
print('Total Day Calls : ',df.total_day_calls.unique())
print('Total Day Charge : ',df.total_day_charge.unique())
print('Total Eve Minutes : ',df.total_eve_minutes.unique())
print('Total Eve Calls : ',df.total_eve_calls.unique())
print('Total Eve Charge : ',df.total_eve_charge.unique())
print('Total Night Minutes : ',df.total_night_minutes.unique())
print('Total Night Calls : ',df.total_night_calls.unique())
print('Total Night Charge : ',df.total_night_charge.unique())
print('Total Intl Minutes : ',df.total_intl_minutes.unique())
print('Total Intl Calls : ',df.total_intl_calls.unique())
print('Total Intl Charge : ',df.total_intl_charge.unique())
print('Number Customer Service Calls : ',df.number_customer_service_calls.unique())
print('Churn : ',df.churn.unique())

"""## Detecting Outliers"""

sns.boxplot(x=df['account_length'])

sns.boxplot(x=df['number_vmail_messages'])

sns.boxplot(x=df['total_day_minutes'])

sns.boxplot(x=df['total_day_calls'])

sns.boxplot(x=df['total_eve_minutes'])

sns.boxplot(x=df['total_eve_calls'])

sns.boxplot(x=df['total_eve_charge'])

sns.boxplot(x=df['total_night_minutes'])

sns.boxplot(x=df['total_night_calls'])

sns.boxplot(x=df['total_night_charge'])

sns.boxplot(x=df['total_intl_minutes'])

sns.boxplot(x=df['total_intl_calls'])

sns.boxplot(x=df['total_intl_charge'])

sns.boxplot(x=df['number_customer_service_calls'])

"""## Remove outliers in all variables"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
data=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
df.shape

"""## Data visualization"""

df.hist(bins=5,figsize=(20,15))
plt.show()

fig, ax=plt.subplots(figsize=(20,5))
sns.countplot(data = df, x='state', order=df['state'].value_counts().index, palette='viridis', hue='churn')
plt.xticks(rotation=90)
plt.xlabel('State', fontsize=10, fontweight='bold')
plt.ylabel('Customers', fontsize=10, fontweight='bold')
plt.title('State wise Customers', fontsize=12, fontweight='bold')
plt.show()

fig2, ax=plt.subplots(figsize=(15,5))
sns.countplot(data = df, x='area_code', order=df['area_code'].value_counts().index, palette='viridis', hue='churn')
plt.xlabel('Area Code', fontsize=10, fontweight='bold')
plt.ylabel('Customers', fontsize=10, fontweight='bold')
plt.title('Area Code wise Customers', fontsize=12, fontweight='bold')
plt.show()

fig3, ax=plt.subplots(figsize=(15,5))
sns.scatterplot(data = df, x='total_day_calls',y='total_day_charge' , palette='viridis')
plt.xlabel('Total Day Calls', fontsize=10, fontweight='bold')
plt.ylabel('Total Day Charge', fontsize=10, fontweight='bold')
plt.title('Day charge v/s Calls', fontsize=12, fontweight='bold')
plt.show()

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='Blues', linewidths=1, )
plt.title("Correlation Matrix for Numeric Features ", size=30)

"""# Data Preparation"""

df['churn'].replace({'no': 0, 'yes': 1}, inplace=True)
df['international_plan'].replace({'no': 0, 'yes': 1}, inplace=True)
df['voice_mail_plan'].replace({'no': 0, 'yes': 1}, inplace=True)

df.drop(columns=['state', 'area_code'], inplace=True)

df['minutes'] = df['total_day_minutes'] + df['total_eve_minutes'] + df['total_night_minutes']
df['calls_cnt'] = df['total_day_calls'] + df['total_eve_calls'] + df['total_night_calls']
df['total_charge'] = df['total_day_charge'] + df['total_eve_charge'] + df['total_night_charge']

df.drop(columns=['total_day_minutes', 'total_eve_minutes', 'total_night_minutes'], inplace=True)
df.drop(columns=['total_day_calls', 'total_eve_calls', 'total_night_calls'], inplace=True)
df.drop(columns=['total_day_charge', 'total_eve_charge', 'total_night_charge'], inplace=True)

df.drop(columns=['total_intl_minutes', 'total_intl_calls'], inplace=True)

df.head()

df.isnull().sum()

df = df.fillna(df.mean())

df.describe()

corr = df.corr()
fig4, ax = plt.subplots(figsize=(15,7))
sns.heatmap(corr,
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values,
            annot=True,cmap="YlGnBu",annot_kws={'size': 12},fmt=".2f")

X = df.drop("churn", axis=1)
y = df["churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80,test_size=0.20,random_state=1)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""# Modelling"""

models = pd.DataFrame(index=['train_acc', 'test_acc'], 
                      columns=['ET','RFC','DC','AB','SVC','GNB'])

"""### ExtraTreesClassifier"""

ET = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0, n_jobs=-1)
ET.fit(X_train, y_train)

models.loc['train_acc','ET'] =accuracy_score(y_train, ET.predict(X_train))

ET_pred = ET.predict(X_test)

accuracy_score(y_test, ET_pred)

ET_cr = classification_report(y_test, ET_pred, output_dict=True)
pd.DataFrame(ET_cr).transpose()

"""### RandomForestClassifier"""

RFC = RandomForestClassifier(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RFC.fit(X_train,y_train)
models.loc['train_acc','RFC']=accuracy_score(y_train, RFC.predict(X_train))

RFC_pred = RFC.predict(X_test)

accuracy_score(y_test, RFC_pred)

RFC_cr = classification_report(y_test, RFC_pred, output_dict=True)
pd.DataFrame(RFC_cr).transpose()

"""### DecisionTreeClassifier"""

DT = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=0)
DT.fit(X_train, y_train)
models.loc['train_acc','DecisionTree'] = accuracy_score(y_train, DT.predict(X_train))

DT_pred = DT.predict(X_test)

accuracy_score(y_test, DT_pred)

DT_cr = classification_report(y_test, DT_pred, output_dict=True)
pd.DataFrame(DT_cr).transpose()

"""### AdaBoostClassifier"""

AB = AdaBoostClassifier(n_estimators=100,  random_state=0)
AB.fit(X_train, y_train)
models.loc['train_acc','AdaBoost'] = accuracy_score(y_train, AB.predict(X_train))

AB_pred = AB.predict(X_test)

accuracy_score(y_test, AB_pred)

AB_cr = classification_report(y_test, AB_pred, output_dict=True)
pd.DataFrame(AB_cr).transpose()

"""### SVC"""

SVC=SVC()
SVC.fit(X_train,y_train)
models.loc['train_acc','SVC']=accuracy_score(y_train,SVC.predict(X_train))

SVC_pred = SVC.predict(X_test)

accuracy_score(y_test, SVC_pred)

SVC_cr = classification_report(y_test, SVC_pred, output_dict=True)
pd.DataFrame(SVC_cr).transpose()

"""### GaussianNB"""

GNB=GaussianNB()
GNB.fit(X_train,y_train)
models.loc['train_acc','GNB']=accuracy_score(y_train,GNB.predict(X_train))

GNB_pred = GNB.predict(X_test)

accuracy_score(y_test, GNB_pred)

GNB_cr = classification_report(y_test, GNB_pred, output_dict=True)
pd.DataFrame(GNB_cr).transpose()

"""### Dataframe Accuracy"""

# Buat variabel acc yang isinya adalah dataframe nilai acc data train dan test pada masing-masing algoritma
acc = pd.DataFrame(columns=['train', 'test'], index=['ExtraTreesClassifier','RandomForestClassifier','DecisionTreeClassifier','AdaBoostClassifier','SVC','GaussianNB'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'ExtraTreesClassifier':ET,'RandomForestClassifier':RFC,'DecisionTreeClassifier':DT,'AdaBoostClassifier':AB,'SVC':SVC,'GaussianNB':GNB}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    acc.loc[name, 'train'] = accuracy_score(y_true=y_train, y_pred=model.predict(X_train)).round(15)*100
    acc.loc[name, 'test'] =accuracy_score(y_true=y_test, y_pred=model.predict(X_test)).round(15)*100

acc

fig, ax = plt.subplots()
acc.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""# Evaluasi"""

prediksi = X_test.iloc[5:6].copy()
pred_dict = {'y_true':y_test[5:6]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi)
 
pd.DataFrame(pred_dict)

prediksi